{"cells":[{"cell_type":"markdown","metadata":{"id":"Yt072OVMJvfi"},"source":["# Preface\n","\n","This first exercise is primarily meant to ensure that everything is working fine. Complete the assignment by filling in code where necessary using Jupyter in Colab."]},{"cell_type":"markdown","metadata":{"id":"d0xxw7nNJvfl"},"source":["# Numpy tutorial\n","You'll need to know some numpy to work with vectors. If you are not familiar to numpy, we recommend to check the following Python/Numpy tutorial:\n","\n","   http://cs231n.github.io/python-numpy-tutorial/\n","\n","We recommend to follow it up to scipy section at least, but learning Matplotlib might be helpful plots learning curves and similar."]},{"cell_type":"markdown","metadata":{"id":"iIC28CQKJvfp"},"source":["# Making sure everything works"]},{"cell_type":"markdown","metadata":{"id":"kmzNluBuJvfu"},"source":["If you are planning to run the labs in your laptop, you'll need to make sure you have Python, Jupyter, and TensorFlow installed. For some help with that, see 'Getting set up' document in  [Egela](https://egela.ehu.eus/course/view.php?id=43863). Please, make all the installations outside the class. \n","\n","Once you've done all of that, you should open this notebook in Jupyter and run the below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZFRfjPrBJvfx","scrolled":true},"outputs":[],"source":["import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"wUDBPhY1Jvf6"},"source":["If that worked as expected, you should be able to run the below a few times and get different outcomes each time."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ACXcHFSxJvf9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641921724192,"user_tz":-60,"elapsed":488,"user":{"displayName":"David Cabestany","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13495857735833713912"}},"outputId":"4a82883d-89da-4acb-8298-bc68612e405f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8353166254236456"]},"metadata":{},"execution_count":4}],"source":["np.random.rand()"]},{"cell_type":"markdown","metadata":{"id":"N3UuTWcxJvgJ"},"source":["Now let's try importing and testing TensorFlow. This can be a bit trickier to install properly. Even once it's installed, running this line should take a few seconds."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_I1vuugJvgL","colab":{"base_uri":"https://localhost:8080/","height":37},"executionInfo":{"status":"ok","timestamp":1641921731595,"user_tz":-60,"elapsed":2995,"user":{"displayName":"David Cabestany","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13495857735833713912"}},"outputId":"93cf59dc-4257-4fa5-f901-8b5ca9df6a17"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.7.0'"]},"metadata":{},"execution_count":5}],"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"iXPMFIXYJvgT"},"source":["First we define some tensor variables."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LVxxljXZJvgY"},"outputs":[],"source":["random_scalar = tf.random.uniform(())"]},{"cell_type":"markdown","metadata":{"id":"b26AvN8JJvgg"},"source":["Then we call a tensorflow function to get its value:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GNcMM5yqJvgh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641921745719,"user_tz":-60,"elapsed":347,"user":{"displayName":"David Cabestany","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13495857735833713912"}},"outputId":"05bf64b7-a26c-400c-faf6-2d3bf6c54f61"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.711256742\n"]}],"source":["tf.print(random_scalar)\n"]},{"cell_type":"markdown","metadata":{"id":"74641zdBJvg1"},"source":["Variables can depend on other variables..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UVqCy5yGJvg3"},"outputs":[],"source":["double_random_scalar = 2 * random_scalar\n","double_random_scalar_gt_one = double_random_scalar > 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rGny3PyzJvhB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641921756272,"user_tz":-60,"elapsed":368,"user":{"displayName":"David Cabestany","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13495857735833713912"}},"outputId":"5ffda3b2-a37d-443f-bc71-d35a08948cf8"},"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]}],"source":["tf.print(double_random_scalar_gt_one)"]},{"cell_type":"markdown","metadata":{"id":"iDj-UbsWJvhL"},"source":["Both TensorFlow and NumPy allow nearly any variable to take the form of a tensor (i.e., a vector, a matrice, or a higher-order such structure):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UOIys8znJvhO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641921763721,"user_tz":-60,"elapsed":795,"user":{"displayName":"David Cabestany","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13495857735833713912"}},"outputId":"15689a71-5d5e-43cc-fa98-24fd6f0612d4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.27802865, 0.59786088, 0.90666511],\n","       [0.48350597, 0.13932249, 0.28518744]])"]},"metadata":{},"execution_count":10}],"source":["np.random.rand(2,3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kExVVqHfJvhW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641921770763,"user_tz":-60,"elapsed":813,"user":{"displayName":"David Cabestany","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13495857735833713912"}},"outputId":"f7074bc5-57a8-4428-8112-836d57bc381f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.606512547 0.325416565 0.817865968]\n"," [0.0228177309 0.417286277 0.20732224]]\n","[[1 0 1]\n"," [0 0 0]]\n"]}],"source":["random_tensor = tf.random.uniform((2,3))\n","double_random_tensor = 2 * random_tensor\n","double_random_tensor_gt_one = double_random_tensor > 1\n","tf.print(random_tensor)\n","tf.print(double_random_tensor_gt_one)\n"]},{"cell_type":"markdown","metadata":{"id":"a_oKdSgLSVp3"},"source":["## 1. Loading the data\n","\n","Let's load the Stanford Sentiment Treebank. The data can be originaly downloaded from here: [the train/dev/test Stanford Sentiment Treebank distribution](http://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip). If you already copied dl4nlp_labs folder to your Colab Notebooks``, you should have the data for this lab dl4nlp_labs/data/trees`.\n","\n","In order to load the data, yiu we'll need to mount your Drive folder first and give the access to the Notebook. This will require one-step authentication. Please when you run the cell below follow the instructions.\n","\n","Once you mount everything, make sure sst_home = 'drive/My Drive/Colab Notebooks/dl4nlp_labs/data/trees/'' is correct path for the data.\n","\n","Please run the cell below to upload the following data files:\n","\n","    dl4nlp_labs/data/trees/train.txt.\n","    dl4nlp_labs/data/trees/dev.txt.\n","    dl4nlp_labs/data/trees/test.txt.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ztEZDk40VGR1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641921821528,"user_tz":-60,"elapsed":26742,"user":{"displayName":"David Cabestany","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13495857735833713912"}},"outputId":"930b7e26-0e17-4100-9193-308c2ffdcb1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84PVrp7EWIvp"},"outputs":[],"source":["# set seed for replicability of results\n","import numpy as np\n","import tensorflow as tf\n","\n","np.random.seed(1)\n","tf.random.set_seed(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lVuCsviDWxsT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641921832387,"user_tz":-60,"elapsed":3239,"user":{"displayName":"David Cabestany","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13495857735833713912"}},"outputId":"2ae38756-1e59-48b6-f6ee-5911182d5dca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training size: 6920\n","Dev size: 872\n","Test size: 1821\n"]}],"source":["# Load the data\n","import re\n","\n","# Let's do 2-way positive/negative classification instead of 5-way    \n","def load_sst_data(path,\n","                  easy_label_map={0:0, 1:0, 2:None, 3:1, 4:1}):\n","    data = []\n","    with open(path) as f:\n","        for i, line in enumerate(f): \n","            example = {}\n","            example['label'] = easy_label_map[int(line[1])]\n","            if example['label'] is None:\n","                continue\n","            \n","            # Strip out the parse information and the phrase labels---we don't need those here\n","            text = re.sub(r'\\s*(\\(\\d)|(\\))\\s*', '', line)\n","            example['text'] = text[1:]\n","            data.append(example)\n","    return data\n","\n","sst_home = 'drive/My Drive/Colab Notebooks/dl4nlp_labs/data/trees/'\n","training_set = load_sst_data(sst_home + 'train.txt')\n","dev_set = load_sst_data(sst_home + 'dev.txt')\n","test_set = load_sst_data(sst_home + 'test.txt')\n","\n","print('Training size: {}'.format(len(training_set)))\n","print('Dev size: {}'.format(len(dev_set)))\n","print('Test size: {}'.format(len(test_set)))"]},{"cell_type":"markdown","metadata":{"id":"fmyZSK-aXSLp"},"source":["## 2. Examining the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3U1XnmkeXVWp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641921839977,"user_tz":-60,"elapsed":368,"user":{"displayName":"David Cabestany","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13495857735833713912"}},"outputId":"e36948e5-589b-4ff1-de42-f9640230c531"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"This is n't a new idea .\",\n"," \"... a sour little movie at its core ; an exploration of the emptiness that underlay the relentless gaiety of the 1920 's ... The film 's ending has a `` What was it all for ? ''\",\n"," 'Made me unintentionally famous -- as the queasy-stomached critic who staggered from the theater and blacked out in the lobby .',\n"," 'The modern-day royals have nothing on these guys when it comes to scandals .',\n"," \"It 's only in fairy tales that princesses that are married for political reason live happily ever after .\",\n"," 'An absurdist spider web .',\n"," 'By no means a slam-dunk and sure to ultimately disappoint the action fans who will be moved to the edge of their seats by the dynamic first act , it still comes off as a touching , transcendent love story .',\n"," \"It 's not a great monster movie .\",\n"," \"Too often , Son of the Bride becomes an exercise in trying to predict when a preordained `` big moment '' will occur and not `` if . ''\",\n"," 'A party-hearty teen flick that scalds like acid .']"]},"metadata":{},"execution_count":15}],"source":["# Print a sample of negative text chunks\n","[example[\"text\"] for example in training_set if example[\"label\"] == 0][:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hTDFfvuaXaY0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641921853465,"user_tz":-60,"elapsed":1102,"user":{"displayName":"David Cabestany","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13495857735833713912"}},"outputId":"dca78e63-318f-449f-989e-8d127f3a4c1c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\",\n"," \"The gorgeously elaborate continuation of `` The Lord of the Rings '' trilogy is so huge that a column of words can not adequately describe co-writer\\\\/director Peter Jackson 's expanded vision of J.R.R. Tolkien 's Middle-earth .\",\n"," 'Singer\\\\/composer Bryan Adams contributes a slew of songs -- a few potential hits , a few more simply intrusive to the story -- but the whole package certainly captures the intended , er , spirit of the piece .',\n"," 'Yet the act is still charming here .',\n"," \"Whether or not you 're enlightened by any of Derrida 's lectures on `` the other '' and `` the self , '' Derrida is an undeniably fascinating and playful fellow .\",\n"," 'Just the labour involved in creating the layered richness of the imagery in this chiaroscuro of madness and light is astonishing .',\n"," 'Part of the charm of Satin Rouge is that it avoids the obvious with humour and lightness .',\n"," \"a screenplay more ingeniously constructed than `` Memento ''\",\n"," \"`` Extreme Ops '' exceeds expectations .\",\n"," 'Good fun , good action , good acting , good dialogue , good pace , good cinematography .']"]},"metadata":{},"execution_count":16}],"source":["# Print a sample of positive text chunks\n","[example[\"text\"] for example in training_set if example[\"label\"] == 1][:10]"]},{"cell_type":"markdown","metadata":{"id":"P0QVgctyJvhr"},"source":["## Assignments\n","### Part 1:"]},{"cell_type":"markdown","metadata":{"id":"zba6bYk3Jvht"},"source":["Write a python function using NumPy to compute the following function of `x`. You can set $\\mu$ to 0 and $\\sigma$ to 1. This happens to be the probability distribution function for a normal distribution, but we're just using it as an arbitrary demo, and you shouldn't use any preexisting code for this particular distribution. You'll likely need to search for relevant NumPy documentation."]},{"cell_type":"markdown","metadata":{"id":"XeUzqLprJvhu"},"source":["![The PDF of the standard normal distribution.](https://drive.google.com/uc?id=11NpGnvDTRhnEkFwDsRYdLKMYDGHUMODM)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YGTHTpqmJvhz"},"outputs":[],"source":["def np_fn(x):\n","  mu = 0\n","  sigma = 1\n","  sq_sigma = np.square(sigma)\n","\n","  stp_one = 1/np.sqrt(2*sq_sigma*np.pi)\n","  stp_two = np.exp(-np.square(x-mu) / (2*sq_sigma))\n","  stp_three = stp_one * stp_two\n","  \n","  return stp_three"]},{"cell_type":"markdown","metadata":{"id":"zS3KgidSJviC"},"source":["Assume `x` is a vector. You should be able to run the following command and get the subsequent result:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sGi3affeJviG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641924116181,"user_tz":-60,"elapsed":2,"user":{"displayName":"David Cabestany","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13495857735833713912"}},"outputId":"093e7a6d-d480-4785-ba38-864d5315c0ac"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.39894228, 0.24197072, 0.05399097, 0.00443185])"]},"metadata":{},"execution_count":67}],"source":["x = np.array([0, 1, 2, 3])\n","np_fn(x)"]},{"cell_type":"markdown","metadata":{"id":"ZddAm-35JviP"},"source":["Expected output: `array([ 0.39894228,  0.24197072,  0.05399097,  0.00443185])\n","`"]},{"cell_type":"markdown","metadata":{"id":"G33QxN7dJviY"},"source":["### Part 2:\n","Now try to write the same function (`tf_fn(x)`) in TensorFlow."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0aUb7TUcJvia"},"outputs":[],"source":["import math as m\n","\n","def tf_fn(x):\n","  mu = 0\n","  sigma = 1\n","  pi = tf.constant(m.pi)\n","  sq_sigma = sigma**2\n","\n","  stp_one = 1/tf.sqrt(2*sq_sigma*pi)\n","  stp_two = tf.exp(-tf.square(x-mu) / (2*sq_sigma))\n","  stp_one = tf.cast(stp_one, tf.float32)\n","  stp_two = tf.cast(stp_two, tf.float32)\n","\n","  print(stp_one, stp_two)\n","  stp_three = stp_one * stp_two\n","  \n","  return stp_three"]},{"cell_type":"markdown","metadata":{"id":"BL_j19TGJvig"},"source":["You should be able to run command below, and get the same output as above."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BG6bmlB9Jvil","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641924785476,"user_tz":-60,"elapsed":3,"user":{"displayName":"David Cabestany","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13495857735833713912"}},"outputId":"87205aad-65fe-4594-f2f1-43ea06197183"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(0.39894223, shape=(), dtype=float32) tf.Tensor([1.         0.60653067 0.13533528 0.011109  ], shape=(4,), dtype=float32)\n","[0.398942232 0.241970703 0.0539909601 0.00443184795]\n"]}],"source":["tf.print(tf_fn(x))"]},{"cell_type":"markdown","metadata":{"id":"kjBUT-D2spyT"},"source":["# Atribution:\n","Adapted by Oier Lopez de Lacalle, Olatz Perez de Viñaspre and Ander Barrena, based on a notebook by Sam Bowman at NYU"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"1. Warming Up.ipynb","provenance":[{"file_id":"15cRuzoKiH9CCIVT6Mdjz3oImzdSXQM3z","timestamp":1541612495844}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}