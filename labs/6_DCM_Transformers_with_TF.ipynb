{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADSUAR_CLARA 6. Transformers_with_TF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d6216b953b6414189570adc931e80ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea02ee2d02454c01aae07a89e3f5f516",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e43e6ca744fa40c3a580084fc310719c",
              "IPY_MODEL_1cf80204a6ef49829d09b3fbe8ea4f11",
              "IPY_MODEL_a92e5c8e950543f38353d44d9c3deec8"
            ]
          }
        },
        "ea02ee2d02454c01aae07a89e3f5f516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e43e6ca744fa40c3a580084fc310719c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c65f4c2b1524611bda65b6309435da9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f06da7feb87d4e55a21d4619077405da"
          }
        },
        "1cf80204a6ef49829d09b3fbe8ea4f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ff6a83b08edd44ee96f69584fbbd1a5c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4dbf0809dde5443abcaa80fa2ac38ce0"
          }
        },
        "a92e5c8e950543f38353d44d9c3deec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d862615d63bf4b009cf25a1208764118",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 6.63kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_835193b830074024a139834b2a585b1b"
          }
        },
        "1c65f4c2b1524611bda65b6309435da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f06da7feb87d4e55a21d4619077405da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff6a83b08edd44ee96f69584fbbd1a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4dbf0809dde5443abcaa80fa2ac38ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d862615d63bf4b009cf25a1208764118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "835193b830074024a139834b2a585b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cf9af69ad6f4bf29b6274c0ba912f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_86980414c0dd44d98b2c7886c6290b6c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a6c7e2c35027489b9906f4bdbc9f5ce9",
              "IPY_MODEL_b8a8dfecf2ac49a68d555da87f909755",
              "IPY_MODEL_bc2e43e5a71f49ca8ad124a5112721c8"
            ]
          }
        },
        "86980414c0dd44d98b2c7886c6290b6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6c7e2c35027489b9906f4bdbc9f5ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5171fc9f498f42cfbf524172b38aabc5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd6515b5b1fc4decb6da454c5bd75f79"
          }
        },
        "b8a8dfecf2ac49a68d555da87f909755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_96175f3db8ee47c9a4d1a954597465ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 526681800,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 526681800,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f3494f6fbd74cdd9234e5fd8daedcfb"
          }
        },
        "bc2e43e5a71f49ca8ad124a5112721c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c3bdcac42db84bc697a11592bff229e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 502M/502M [00:26&lt;00:00, 36.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a87197b4ee741299a4cdaf488d8d3ee"
          }
        },
        "5171fc9f498f42cfbf524172b38aabc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd6515b5b1fc4decb6da454c5bd75f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96175f3db8ee47c9a4d1a954597465ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f3494f6fbd74cdd9234e5fd8daedcfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3bdcac42db84bc697a11592bff229e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a87197b4ee741299a4cdaf488d8d3ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e76add8ad496432daa418743cead860a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d9e27501c1244241999e3061d6898361",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_24420aa92fce4be6b72858f8f7b2b6b0",
              "IPY_MODEL_cea8efa2b44d4948a5b35f1aba04b2c3",
              "IPY_MODEL_7d442b40220a4616875a859f8aab7791"
            ]
          }
        },
        "d9e27501c1244241999e3061d6898361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24420aa92fce4be6b72858f8f7b2b6b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cedc5255c66243c386cfff29427e3d3e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_257e671c2e464ee180db5714a5a87e2c"
          }
        },
        "cea8efa2b44d4948a5b35f1aba04b2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8134b79c62a54fa8bd0fe4413246fce6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4649285197314e068b51a0def1962d7d"
          }
        },
        "7d442b40220a4616875a859f8aab7791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_299d00bed0054732a7834417c6bfe01f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 208k/208k [00:00&lt;00:00, 1.41MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9fb424c76d774aad9c1364a43986e6c8"
          }
        },
        "cedc5255c66243c386cfff29427e3d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "257e671c2e464ee180db5714a5a87e2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8134b79c62a54fa8bd0fe4413246fce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4649285197314e068b51a0def1962d7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "299d00bed0054732a7834417c6bfe01f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9fb424c76d774aad9c1364a43986e6c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4086224eb63c4b71a7188dc81a58d8fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_611b9afd1c3245fc8457e0edc1cef561",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8d79a892c9634a36be95cb6390a36a24",
              "IPY_MODEL_8e6eb2e3f9324cfab7b001ab453619ff",
              "IPY_MODEL_ba9f848072e241b48a2e6e7f72caf88f"
            ]
          }
        },
        "611b9afd1c3245fc8457e0edc1cef561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d79a892c9634a36be95cb6390a36a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0db8550fe23f4e41ae3702b80369cba2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dccf1f3e6d6949e999662d3693d6fa69"
          }
        },
        "8e6eb2e3f9324cfab7b001ab453619ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_138398fcbd2d46668a2b73b7c57327d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77abae20f0ad493190c7cea3e0982404"
          }
        },
        "ba9f848072e241b48a2e6e7f72caf88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c51acd3d0ccc43b3bfbfe32d139fecf8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 751B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e09d5c78c7a43c69089618528b0c95c"
          }
        },
        "0db8550fe23f4e41ae3702b80369cba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dccf1f3e6d6949e999662d3693d6fa69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "138398fcbd2d46668a2b73b7c57327d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77abae20f0ad493190c7cea3e0982404": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c51acd3d0ccc43b3bfbfe32d139fecf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e09d5c78c7a43c69089618528b0c95c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3ad121a06c24cb19eee5aea96350821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e8cbb10b645a4fccba4e314f634db0d4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1db46a883db041888ddda32a2c0465d9",
              "IPY_MODEL_be7ee669bc724049b010aa849ffe5e0e",
              "IPY_MODEL_ae0e275a4caa4041bb886637b87d1654"
            ]
          }
        },
        "e8cbb10b645a4fccba4e314f634db0d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1db46a883db041888ddda32a2c0465d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c77449e6de7b49e9901d9451bf74a2f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19380cc3c260472193beb2520cdc07cb"
          }
        },
        "be7ee669bc724049b010aa849ffe5e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5d081c10111747b9ae6dcd0edf962888",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80eb1bb51d4c48c2ab868add3fd3f490"
          }
        },
        "ae0e275a4caa4041bb886637b87d1654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ca8b6890ccc44f59afbce72ab922143",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 426k/426k [00:00&lt;00:00, 753kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05f1d004f0de40ca847584e29e5f2952"
          }
        },
        "c77449e6de7b49e9901d9451bf74a2f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19380cc3c260472193beb2520cdc07cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d081c10111747b9ae6dcd0edf962888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80eb1bb51d4c48c2ab868add3fd3f490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ca8b6890ccc44f59afbce72ab922143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05f1d004f0de40ca847584e29e5f2952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imyaVBbcIBVq"
      },
      "source": [
        "# Lab 6: Sentiment Analysis with fine-tuned Transformers\n",
        "\n",
        "In this lab session, you will fine-tune a **Transformer** based pre-trained language model for sentiment analysis. Transfer learning with large pre-trained language models has been shown to be successful strategy to achieve state-of-the-art performances. In this lab we'll learn how to do transfer learning with large pre-trained neural language models like BERT. \n",
        "\n",
        "More concretely, in this lab session will learn the following:\n",
        "\n",
        "- Deploy and fine-tune transformers from the [Hugging Face library](https://github.com/huggingface/transformers)\n",
        "- Preprocessing data for transformers archicture (word piece tokenizatiin)\n",
        "- Implementation of Transformer-based classifier\n",
        "\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "## Transfer Learning\n",
        " \n",
        "Figure below shows how to fine-tune a transformer on a downstream task. Here, the fine-tuning task is sentiment analysis of movie reviews. As learned from theory, we will use the knowledge encoded in the Transformer to learn better our target task. So our sentiment classifier has two main components: 1) the text encoder based on BERT (which doesn't know anything about sentiments, but knows something about English), and 2) the component dedicated to sentiment classification (a simple feed-forward layer). In other words, BERT will generate the sentence embeddings of the input and pass to the classifier layer to the prediction. When we fine-tune our classifier we'll change BERT's parameters as well, and make it to learn specific aspects of the task.\n",
        "\n",
        " ![](http://ixa2.si.ehu.es/~jibloleo/uc3m_dl4nlp/img/fine-tuning.png)\n",
        "\n",
        "\n",
        "Advantages of these types of architectures and learning:\n",
        "\n",
        "- Unlimited amount of unlabelled text data can be scraped from the web with very little effort to train a large language model.\n",
        "- Transformer is a feed-forward architecture that allows highly parallelized, efficient training on huge datasets, with the objective of simply predicting words based on their context ([check the tutorial on strategy learning for sequence classification](https://colab.research.google.com/drive/1yWaLpCWImXZE2fPV0ZYDdWWI8f52__9A#scrollTo=MGqVkG2-7qfu)).\n",
        "- Although pre-training a language model can be expensive, fine-tuning can be done in a single GPU most of the times, as tipically it requiere few learning epochs. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWHDCCqPIBVr"
      },
      "source": [
        "## 1. Loading the data\n",
        "We'll use the same data for sentiement analysis used in previous sessions. So first, we need to mount our Drive account in order to get access to the sentiment analysis data ( Stanford Sentiment Treebank)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihLkOMT9OJDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d6f3c6-e0bd-4828-a1e7-76614589f0f3"
      },
      "source": [
        "# Mount Drive files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZhrDTCkIBVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b22ab874-cae4-4ef1-bd8e-acc5479d99dc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "## for replicability of results\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "\n",
        "# Let's do 2-way positive/negative classification instead of 5-way    \n",
        "def load_sst_data(path,\n",
        "                  easy_label_map={0:0, 1:0, 2:None, 3:1, 4:1}):\n",
        "    data = []\n",
        "    with open(path) as f:\n",
        "        for i, line in enumerate(f): \n",
        "            example = {}\n",
        "            example['label'] = easy_label_map[int(line[1])]\n",
        "            if example['label'] is None:\n",
        "                continue\n",
        "            \n",
        "            # Strip out the parse information and the phrase labels---we don't need those here\n",
        "            text = re.sub(r'\\s*(\\(\\d)|(\\))\\s*', '', line)\n",
        "            example['text'] = text[1:]\n",
        "            data.append(example)\n",
        "    data = pd.DataFrame(data)\n",
        "    return data\n",
        "\n",
        "def pretty_print(example):\n",
        "    print('Label: {}\\nText: {}'.format(example['label'], example['text']))\n",
        "\n",
        "sst_home = 'drive/My Drive/Colab Notebooks/dl4nlp_labs/data/trees/'\n",
        "training_set = load_sst_data(sst_home+'/train.txt')\n",
        "dev_set = load_sst_data(sst_home+'/dev.txt')\n",
        "test_set = load_sst_data(sst_home+'/test.txt')\n",
        "\n",
        "# Shuffle dataset\n",
        "training_set = shuffle(training_set)\n",
        "dev_set = shuffle(dev_set)\n",
        "test_set = shuffle(test_set)\n",
        "\n",
        "# Obtain text and label vectors\n",
        "train_texts = training_set.text\n",
        "train_labels = training_set.label\n",
        "\n",
        "dev_texts = dev_set.text\n",
        "dev_labels = dev_set.label\n",
        "\n",
        "test_texts = test_set.text\n",
        "test_labels = test_set.label\n",
        "\n",
        "\n",
        "print('Training size: {}'.format(len(training_set)))\n",
        "print('Dev size: {}'.format(len(dev_set)))\n",
        "print('Test size: {}'.format(len(test_set)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training size: 6920\n",
            "Dev size: 872\n",
            "Test size: 1821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZqxg504JNIv"
      },
      "source": [
        "## 2. Installing and seting up the Transformers library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I1LnTA4II71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8362f9cd-1ee0-4470-8cf1-613640c3cea4"
      },
      "source": [
        "# https://blog.tensorflow.org/2019/11/hugging-face-state-of-art-natural.html\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 33.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4ZJAgAVelDa"
      },
      "source": [
        "Once the transformers library is installed, we can use it directly just creating three object of two classes:\n",
        "\n",
        "- **The tokenizer class**: the tokenizer class takes care of converting input  string in tensors of integers which are indices in a model vocabulary. The tokenization varies according to the model, therefore each model has its own tokenizer.\n",
        "\n",
        "- **The model class**: the model class holds the neural network modeling logic itself. When using a TensorFlow model, it inherits from tf.keras.layers. Layer which means it can be used very simply by the Keras’ fit API or make more complicated stuff. \n",
        "\n",
        "There is also **configuration class** that is also required unless you are not using the default values. With the configuration class we indicate everything related to hyperparaters such as number of layers, dropout and so on. Below is an example of a BERT configuration file, for the pre-trained weights bert-base-cased. \n",
        "\n",
        "```\n",
        "{\n",
        "  \"attention_probs_dropout_prob\": 0.1,\n",
        "  \"hidden_act\": \"gelu\",\n",
        "  \"hidden_dropout_prob\": 0.1,\n",
        "  \"hidden_size\": 768,\n",
        "  \"initializer_range\": 0.02,\n",
        "  \"intermediate_size\": 3072,\n",
        "  \"max_position_embeddings\": 512,\n",
        "  \"num_attention_heads\": 12,\n",
        "  \"num_hidden_layers\": 12,\n",
        "  \"type_vocab_size\": 2,\n",
        "  \"vocab_size\": 28996\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7FLj9htJFJW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251,
          "referenced_widgets": [
            "6d6216b953b6414189570adc931e80ff",
            "ea02ee2d02454c01aae07a89e3f5f516",
            "e43e6ca744fa40c3a580084fc310719c",
            "1cf80204a6ef49829d09b3fbe8ea4f11",
            "a92e5c8e950543f38353d44d9c3deec8",
            "1c65f4c2b1524611bda65b6309435da9",
            "f06da7feb87d4e55a21d4619077405da",
            "ff6a83b08edd44ee96f69584fbbd1a5c",
            "4dbf0809dde5443abcaa80fa2ac38ce0",
            "d862615d63bf4b009cf25a1208764118",
            "835193b830074024a139834b2a585b1b",
            "0cf9af69ad6f4bf29b6274c0ba912f4b",
            "86980414c0dd44d98b2c7886c6290b6c",
            "a6c7e2c35027489b9906f4bdbc9f5ce9",
            "b8a8dfecf2ac49a68d555da87f909755",
            "bc2e43e5a71f49ca8ad124a5112721c8",
            "5171fc9f498f42cfbf524172b38aabc5",
            "cd6515b5b1fc4decb6da454c5bd75f79",
            "96175f3db8ee47c9a4d1a954597465ec",
            "6f3494f6fbd74cdd9234e5fd8daedcfb",
            "c3bdcac42db84bc697a11592bff229e0",
            "7a87197b4ee741299a4cdaf488d8d3ee",
            "e76add8ad496432daa418743cead860a",
            "d9e27501c1244241999e3061d6898361",
            "24420aa92fce4be6b72858f8f7b2b6b0",
            "cea8efa2b44d4948a5b35f1aba04b2c3",
            "7d442b40220a4616875a859f8aab7791",
            "cedc5255c66243c386cfff29427e3d3e",
            "257e671c2e464ee180db5714a5a87e2c",
            "8134b79c62a54fa8bd0fe4413246fce6",
            "4649285197314e068b51a0def1962d7d",
            "299d00bed0054732a7834417c6bfe01f",
            "9fb424c76d774aad9c1364a43986e6c8",
            "4086224eb63c4b71a7188dc81a58d8fb",
            "611b9afd1c3245fc8457e0edc1cef561",
            "8d79a892c9634a36be95cb6390a36a24",
            "8e6eb2e3f9324cfab7b001ab453619ff",
            "ba9f848072e241b48a2e6e7f72caf88f",
            "0db8550fe23f4e41ae3702b80369cba2",
            "dccf1f3e6d6949e999662d3693d6fa69",
            "138398fcbd2d46668a2b73b7c57327d4",
            "77abae20f0ad493190c7cea3e0982404",
            "c51acd3d0ccc43b3bfbfe32d139fecf8",
            "6e09d5c78c7a43c69089618528b0c95c",
            "f3ad121a06c24cb19eee5aea96350821",
            "e8cbb10b645a4fccba4e314f634db0d4",
            "1db46a883db041888ddda32a2c0465d9",
            "be7ee669bc724049b010aa849ffe5e0e",
            "ae0e275a4caa4041bb886637b87d1654",
            "c77449e6de7b49e9901d9451bf74a2f4",
            "19380cc3c260472193beb2520cdc07cb",
            "5d081c10111747b9ae6dcd0edf962888",
            "80eb1bb51d4c48c2ab868add3fd3f490",
            "2ca8b6890ccc44f59afbce72ab922143",
            "05f1d004f0de40ca847584e29e5f2952"
          ]
        },
        "outputId": "7f4ac619-7cad-45a3-ba86-273858764235"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
        "\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d6216b953b6414189570adc931e80ff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cf9af69ad6f4bf29b6274c0ba912f4b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e76add8ad496432daa418743cead860a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4086224eb63c4b71a7188dc81a58d8fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3ad121a06c24cb19eee5aea96350821",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U_bMFqMcINb"
      },
      "source": [
        "Next we will define two helper function to 1) extract features from the tokenizer (`convert_examples_to_features`) and 2) convert the features to `tf.data.Dataset` object class (`convert_features_to_tf_dataset`). `tf.data.Dataset` is a convinient API that helps managing and iterating in efficient way the input and output data of the model.  For more information you can check the API in tensorflow web page: https://www.tensorflow.org/api_docs/python/tf/data/Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAolNiqWJmM3"
      },
      "source": [
        "from transformers import InputFeatures\n",
        "\n",
        "def convert_examples_to_features(texts, labels):\n",
        "  labels = list(labels)\n",
        "  batch_encoding = tokenizer.batch_encode_plus(texts, max_length=128, pad_to_max_length=True)\n",
        "\n",
        "  features = []\n",
        "  for i in range(len(texts)):\n",
        "      inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
        "\n",
        "      feature = InputFeatures(**inputs, label=labels[i])\n",
        "      features.append(feature)\n",
        "\n",
        "  for i, example in enumerate(texts[:5]):\n",
        "      print(\"*** Example ***\")\n",
        "      print(\"text: %s\" % (example))\n",
        "      print(\"features: %s\" % features[i])\n",
        "\n",
        "  return features\n",
        "\n",
        "def convert_features_to_tf_dataset(features):\n",
        "  def gen():\n",
        "      for ex in features:\n",
        "          yield (\n",
        "              {\n",
        "                  \"input_ids\": ex.input_ids,\n",
        "                  \"attention_mask\": ex.attention_mask,\n",
        "                  \"token_type_ids\": ex.token_type_ids,\n",
        "              },\n",
        "              ex.label,\n",
        "          )\n",
        "  dataset = tf.data.Dataset.from_generator(gen, \n",
        "                                           ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
        "                                           (\n",
        "                                               {\n",
        "                                                \"input_ids\": tf.TensorShape([None]),\n",
        "                                                \"attention_mask\": tf.TensorShape([None]),\n",
        "                                                \"token_type_ids\": tf.TensorShape([None])\n",
        "                                                },\n",
        "                                            tf.TensorShape([]),\n",
        "                                            ))\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2OE1lWbh3P7"
      },
      "source": [
        "Let's preprocess the training and development sets. Note that we use the `tf.data.Dataset` API to set the batch size to 32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r1LPqLIaW4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69959864-c755-4794-e6db-14b26583b893"
      },
      "source": [
        "train_features = convert_examples_to_features(train_texts, train_labels)\n",
        "train_dataset = convert_features_to_tf_dataset(train_features)\n",
        "\n",
        "dev_features = convert_examples_to_features(dev_texts, dev_labels)\n",
        "dev_dataset = convert_features_to_tf_dataset(dev_features)\n",
        "\n",
        "train_dataset = train_dataset.shuffle(100).batch(32)\n",
        "dev_dataset = dev_dataset.batch(32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Example ***\n",
            "text: It is dark , brooding and slow , and takes its central idea way too seriously .\n",
            "features: InputFeatures(input_ids=[101, 1135, 1110, 1843, 117, 9304, 13465, 1158, 1105, 3345, 117, 1105, 2274, 1157, 2129, 1911, 1236, 1315, 5536, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "text: To honestly address the flaws inherent in how medical aid is made available to American workers , a more balanced or fair portrayal of both sides will be needed .\n",
            "features: InputFeatures(input_ids=[101, 1706, 12051, 4134, 1103, 24132, 17575, 1107, 1293, 2657, 4256, 1110, 1189, 1907, 1106, 1237, 3239, 117, 170, 1167, 12591, 1137, 4652, 14513, 1104, 1241, 3091, 1209, 1129, 1834, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "text: A sad and rote exercise in milking a played-out idea -- a straight guy has to dress up in drag -- that shockingly manages to be even worse than its title would imply .\n",
            "features: InputFeatures(input_ids=[101, 138, 6782, 1105, 24692, 1162, 6730, 1107, 6831, 1158, 170, 1307, 118, 1149, 1911, 118, 118, 170, 2632, 2564, 1144, 1106, 3642, 1146, 1107, 8194, 118, 118, 1115, 19196, 1193, 8701, 1106, 1129, 1256, 4146, 1190, 1157, 1641, 1156, 21276, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "text: Ken Russell would love this .\n",
            "features: InputFeatures(input_ids=[101, 5928, 5023, 1156, 1567, 1142, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "*** Example ***\n",
            "text: An incredibly irritating comedy about thoroughly vacuous people ... manages to embody the worst excesses of nouvelle vague without any of its sense of fun or energy .\n",
            "features: InputFeatures(input_ids=[101, 1760, 12170, 178, 14791, 24558, 3789, 1164, 12678, 191, 7409, 8163, 1234, 119, 119, 119, 8701, 1106, 9712, 14637, 1103, 4997, 10116, 1279, 1104, 1185, 19581, 4838, 14673, 1443, 1251, 1104, 1157, 2305, 1104, 4106, 1137, 2308, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "text: People cinema at its finest .\n",
            "features: InputFeatures(input_ids=[101, 2563, 7678, 1120, 1157, 10812, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "*** Example ***\n",
            "text: Irwin is a man with enough charisma and audacity to carry a dozen films , but this particular result is ultimately held back from being something greater .\n",
            "features: InputFeatures(input_ids=[101, 18819, 1110, 170, 1299, 1114, 1536, 22572, 26464, 1918, 1105, 12686, 1810, 9041, 1106, 3564, 170, 5955, 2441, 117, 1133, 1142, 2440, 1871, 1110, 4444, 1316, 1171, 1121, 1217, 1380, 3407, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "text: If you 've ever entertained the notion of doing what the title of this film implies , what Sex With Strangers actually shows may put you off the idea forever .\n",
            "features: InputFeatures(input_ids=[101, 1409, 1128, 112, 1396, 1518, 23745, 1103, 9162, 1104, 1833, 1184, 1103, 1641, 1104, 1142, 1273, 12942, 117, 1184, 9850, 1556, 19153, 1116, 2140, 2196, 1336, 1508, 1128, 1228, 1103, 1911, 5221, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "text: There ought to be a directing license , so that Ed Burns can have his revoked .\n",
            "features: InputFeatures(input_ids=[101, 1247, 11454, 1106, 1129, 170, 10404, 5941, 117, 1177, 1115, 5316, 9608, 1169, 1138, 1117, 25538, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "text: It 's not that Kung Pow is n't funny some of the time -- it just is n't any funnier than bad martial arts movies are all by themselves , without all Oedekerk 's impish augmentation .\n",
            "features: InputFeatures(input_ids=[101, 1135, 112, 188, 1136, 1115, 24120, 18959, 2246, 1110, 183, 112, 189, 6276, 1199, 1104, 1103, 1159, 118, 118, 1122, 1198, 1110, 183, 112, 189, 1251, 4106, 12682, 1190, 2213, 8317, 3959, 5558, 1132, 1155, 1118, 2310, 117, 1443, 1155, 152, 15018, 4188, 1377, 112, 188, 24034, 2944, 12686, 14294, 1891, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZgauVk5jNhd"
      },
      "source": [
        "The results of the tokenizer can be seen in the cell below. There are some differences if vary the tokenizer, but most of them provide the following information. \n",
        "\n",
        "- `input_ids`: list of token ids to be fed to a model. Remember that the tokens are subwords, and new tokens are included to indicate sentence separation or ending (`[SEP]`) as well as `[CLS]` token that allow the sentence classification .\n",
        "\n",
        "- `token_type_ids`: list of token type ids to be fed to a model. \n",
        "\n",
        "- `attention_mask`: list of indices specifying which tokens should be attended to by the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aue9cJVx_N65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b27965a-7c45-4dbd-b76c-7b6591f7ba72"
      },
      "source": [
        "# take one bacth of 32 examples.\n",
        "instance = list(train_dataset.take(1).as_numpy_iterator())\n",
        "print(instance)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[({'input_ids': array([[  101,  1135,   112, ...,     0,     0,     0],\n",
            "       [  101, 19143,  1200, ...,     0,     0,     0],\n",
            "       [  101,  1409,  1175, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  101,  9352, 24851, ...,     0,     0,     0],\n",
            "       [  101,  2409,  1157, ...,     0,     0,     0],\n",
            "       [  101,  2268, 12062, ...,     0,     0,     0]], dtype=int32), 'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32), 'token_type_ids': array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)}, array([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
            "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1]))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GorwYEWOcFWs"
      },
      "source": [
        "## 3. Understanding the tokenizer\n",
        "\n",
        "When we preprocess the input text to be fed in BERT like encoder, we tipically make three steps: \n",
        "\n",
        "1. Break words into tokens (subwords). \n",
        "2. Add the special tokens such as `[CLS]` and `[SEP]`. These special tokens are already included in the model's vocabulary, so they have their own token id.\n",
        "3. Substitute the tokens with their corresponding ids. After this step will get the proper shape for BERT. \n",
        "\n",
        "The code cell bellow shows the results of the three steps. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFDfUY1UcWzS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12555d70-b96d-4a37-b0d1-319883032411"
      },
      "source": [
        "sentence1 = \"a visually stunning rumination on love.\"\n",
        "sentence2 = \"There ought to be a directing license, so that Ed Burns can have his revoked.\"\n",
        "\n",
        "# Tokenize sentence\n",
        "sentence1_tokenized = tokenizer.tokenize(sentence1)\n",
        "print('0. INPUT SENTENCE: {}'.format(sentence1))\n",
        "print('1. TOKENIZED SENTENCE: {}'.format(sentence1_tokenized))\n",
        "\n",
        "# Add Special tokens\n",
        "sentence1_tokenized_with_special_tokens = ['[CLS]'] + sentence1_tokenized + ['[SEP]']\n",
        "print('2. ADD [CLS], [SEP]: {}'.format(sentence1_tokenized_with_special_tokens))\n",
        "sentence1_ids = tokenizer.convert_tokens_to_ids(sentence1_tokenized_with_special_tokens)\n",
        "\n",
        "# Convert to ids\n",
        "print('3. SENTENCE IDS: {}'.format(sentence1_ids))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0. INPUT SENTENCE: a visually stunning rumination on love.\n",
            "1. TOKENIZED SENTENCE: ['a', 'visually', 'stunning', 'r', '##umi', '##nation', 'on', 'love', '.']\n",
            "2. ADD [CLS], [SEP]: ['[CLS]', 'a', 'visually', 'stunning', 'r', '##umi', '##nation', 'on', 'love', '.', '[SEP]']\n",
            "3. SENTENCE IDS: [101, 170, 19924, 15660, 187, 14088, 9199, 1113, 1567, 119, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_68U0jC81wFA"
      },
      "source": [
        "### Exercise 1:\n",
        "- Can you see what happened to \"rumination\" after the tokenization? \n",
        "- Can you identify the token ids for [CLS] and [SEP]?\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. \"Rumination\" is an Out Of Vocabulary word so we can split it apart. Therefore, the word \"rumination\" has been split into three parts \"r\", \"umi\" and \"nation\". This happens because in the English language you can find words inside other words. So, for example with \"nation\" you can form other words, and it is good that it is in the dictionary just as \"nation\". You can use it for \"resonation\" or \"vibration\".\n",
        "The ## means that you paste that part of the word (or could be a word itself with another one). And also it says that you do not have put there an space, because that segment is together with another in the sentence, altough they are saved different in the vocabulary.\n",
        "2. Yes, the token ids for [CLS] is 101 and for [SEP] is 102."
      ],
      "metadata": {
        "id": "PnXgV_bfW3pS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmPo2_4twYmE"
      },
      "source": [
        "The three steps can be done with `encode` or `batch_encode_plus` functions. The first function takes single string and convert is to ids. Then second function is more convinient to preprocess larger input data. It returns all the requiered information (input_ids, token_type_ids, attention_mask, etc) in a python dictionary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTYbni402ES0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18f1653-4662-435d-91ea-ec82ea80d2b5"
      },
      "source": [
        "# how tokenize and get the token ids with one funtions\n",
        "sentence1_ids = tokenizer.encode(sentence1, add_special_tokens=True)\n",
        "\n",
        "print('SENTENCE IDS: {}'.format(sentence1_ids))\n",
        "\n",
        "# there are more convinient methods to preprocess the input data. \n",
        "batch_encoding = tokenizer.batch_encode_plus(\n",
        "        [sentence1], max_length=128, pad_to_max_length=True,\n",
        "    )\n",
        "print('ENCODE PLUS: {}'.format(batch_encoding))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SENTENCE IDS: [101, 170, 19924, 15660, 187, 14088, 9199, 1113, 1567, 119, 102]\n",
            "ENCODE PLUS: {'input_ids': [[101, 170, 19924, 15660, 187, 14088, 9199, 1113, 1567, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhRQkPRa2KBL"
      },
      "source": [
        "### Two sentences as input\n",
        "\n",
        "As you have seen in the theoretical part BERT is a masked language models that learns predicting masked words, and in addition it predicts if next sentence belongs after the first one. That's why BERT's tokenizer is ready to have two sentences as input. This way preprocessing the data is interesting for task like Semantic Textual Similiraty and Natural Language Inference. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2qZJTkFq8y6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2291761e-8d76-46bc-df24-1621a0904646"
      },
      "source": [
        "# how tokenize and get the token ids with one funtions\n",
        "sentence_pair_ids = tokenizer.encode(text=sentence1, text_pair=sentence2, add_special_tokens=True)\n",
        "\n",
        "\n",
        "# there are more convinient methods to preprocess the input data. \n",
        "batch_encoding = tokenizer.batch_encode_plus(\n",
        "        [(sentence1, sentence2)], max_length=128, pad_to_max_length=True,\n",
        "    )\n",
        "\n",
        "print(\"SENTENCE PAIR IDS: {}\".format(sentence_pair_ids))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SENTENCE PAIR IDS: [101, 170, 19924, 15660, 187, 14088, 9199, 1113, 1567, 119, 102, 1247, 11454, 1106, 1129, 170, 10404, 5941, 117, 1177, 1115, 5316, 9608, 1169, 1138, 1117, 25538, 119, 102]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSeX9VzaFOAY"
      },
      "source": [
        "### Exercise 2:\n",
        "- From the IDs can you say which ids correspond to the first sentence and which to the second one? "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, because you can see in the middle of the line \"SENTENCE PAIR IDS\" that there is a 102, that means there is a [SEP], and then continues. So, this marks the end of the first sentence. We can also do tokenizer.convert_ids_to_tokens in order to see the sentence and when it splits."
      ],
      "metadata": {
        "id": "xdDJ9KrVYJoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(sentence_pair_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3DCHcHqZDYf",
        "outputId": "0e63d683-58e2-4c67-a023-5d486abc6b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'a',\n",
              " 'visually',\n",
              " 'stunning',\n",
              " 'r',\n",
              " '##umi',\n",
              " '##nation',\n",
              " 'on',\n",
              " 'love',\n",
              " '.',\n",
              " '[SEP]',\n",
              " 'There',\n",
              " 'ought',\n",
              " 'to',\n",
              " 'be',\n",
              " 'a',\n",
              " 'directing',\n",
              " 'license',\n",
              " ',',\n",
              " 'so',\n",
              " 'that',\n",
              " 'Ed',\n",
              " 'Burns',\n",
              " 'can',\n",
              " 'have',\n",
              " 'his',\n",
              " 'revoked',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D80JtwZbWJ7C"
      },
      "source": [
        "## 4. Fine-tune BERT as Sentence Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vWeYpxdCmtC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b00f29c-d574-4d9c-ec4a-4c43bf2c176c"
      },
      "source": [
        "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "\n",
        "# Train and evaluate using tf.keras.Model.fit()\n",
        "history = model.fit(train_dataset, epochs=3, validation_data=dev_dataset)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "217/217 [==============================] - 478s 2s/step - loss: 0.3743 - accuracy: 0.8361 - val_loss: 0.2422 - val_accuracy: 0.9071\n",
            "Epoch 2/3\n",
            "217/217 [==============================] - 435s 2s/step - loss: 0.1535 - accuracy: 0.9462 - val_loss: 0.2852 - val_accuracy: 0.9002\n",
            "Epoch 3/3\n",
            "217/217 [==============================] - 435s 2s/step - loss: 0.0591 - accuracy: 0.9805 - val_loss: 0.3983 - val_accuracy: 0.8979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMfta2vyKCXt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "ffe595f4-b131-478f-a878-42c1ef69228f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aeyowf06K11o"
      },
      "source": [
        "A nice feature when fine-tuning a large model is that we do not need to train many epochs (the number of epochs depends on the size of the training set). In this case, it looks like just one epoch can be enough. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EsEkO3uG1et"
      },
      "source": [
        "Once the model is fine-tuned for sentiment analysis we could evaluate it on the test set. In this we need to tokenized and convert to ids the input too. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KFUtfXzImAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05e04a5-8a74-42c8-bfbf-c2665969d652"
      },
      "source": [
        "test_features = convert_examples_to_features(test_texts, test_labels)\n",
        "test_dataset = convert_features_to_tf_dataset(test_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Example ***\n",
            "text: With Danilo Donati 's witty designs and Dante Spinotti 's luscious cinematography , this might have made a decent children 's movie -- if only Benigni had n't insisted on casting himself in the title role .\n",
            "features: InputFeatures(input_ids=[101, 1556, 21555, 2858, 1790, 11745, 112, 188, 20787, 2340, 5054, 1105, 9406, 22878, 15719, 1182, 112, 188, 181, 1361, 9589, 7678, 22556, 117, 1142, 1547, 1138, 1189, 170, 11858, 1482, 112, 188, 2523, 118, 118, 1191, 1178, 3096, 11368, 1182, 1125, 183, 112, 189, 6744, 1113, 9616, 1471, 1107, 1103, 1641, 1648, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "*** Example ***\n",
            "text: Their film falters , however , in its adherence to the Disney philosophy of required poignancy , a salute that I 'd hoped the movie would avoid .\n",
            "features: InputFeatures(input_ids=[101, 2397, 1273, 175, 1348, 5759, 117, 1649, 117, 1107, 1157, 8050, 21634, 1106, 1103, 5712, 5027, 1104, 2320, 185, 8136, 12149, 7232, 117, 170, 22321, 1115, 146, 112, 173, 4320, 1103, 2523, 1156, 3644, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "text: Interacting eyeball-to-eyeball and toe-to-toe , Hopkins and Norton are a winning combination -- but Fiennes steals ` Red Dragon ' right from under their noses .\n",
            "features: InputFeatures(input_ids=[101, 11300, 11179, 1158, 2552, 5892, 118, 1106, 118, 2552, 5892, 1105, 12514, 118, 1106, 118, 12514, 117, 10055, 1105, 10685, 1132, 170, 2183, 4612, 118, 118, 1133, 17355, 26042, 1116, 16867, 169, 2156, 6891, 112, 1268, 1121, 1223, 1147, 3678, 1116, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "*** Example ***\n",
            "text: Aspires for the piquant but only really achieves a sort of ridiculous sourness .\n",
            "features: InputFeatures(input_ids=[101, 1249, 20082, 1116, 1111, 1103, 185, 28101, 27280, 1133, 1178, 1541, 5515, 1116, 170, 3271, 1104, 9944, 17948, 1757, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "text: Exquisitely acted and masterfully if preciously interwoven ... -LRB- the film -RRB- addresses in a fascinating , intelligent manner the intermingling of race , politics and local commerce .\n",
            "features: InputFeatures(input_ids=[101, 16409, 26089, 1193, 5376, 1105, 3283, 5834, 1191, 9692, 1193, 9455, 12821, 7912, 119, 119, 119, 118, 149, 22672, 118, 1103, 1273, 118, 155, 22672, 118, 11869, 1107, 170, 19601, 117, 9998, 4758, 1103, 9455, 5031, 1979, 1104, 1886, 117, 4039, 1105, 1469, 10678, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6EjtjScENVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e14e5c4-f38b-45b8-a6e2-0fade6fb74e3"
      },
      "source": [
        "test_dataset = test_dataset.batch(32)\n",
        "instances = list(test_dataset.take(1).as_numpy_iterator())\n",
        "instances"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[({'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n",
              "          [1, 1, 1, ..., 0, 0, 0],\n",
              "          [1, 1, 1, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [1, 1, 1, ..., 0, 0, 0],\n",
              "          [1, 1, 1, ..., 0, 0, 0],\n",
              "          [1, 1, 1, ..., 0, 0, 0]], dtype=int32),\n",
              "   'input_ids': array([[  101,  1556, 21555, ...,     0,     0,     0],\n",
              "          [  101,  2397,  1273, ...,     0,     0,     0],\n",
              "          [  101, 11300, 11179, ...,     0,     0,     0],\n",
              "          ...,\n",
              "          [  101,   146,  4819, ...,     0,     0,     0],\n",
              "          [  101, 26517,  8743, ...,     0,     0,     0],\n",
              "          [  101,  1109,  2905, ...,     0,     0,     0]], dtype=int32),\n",
              "   'token_type_ids': array([[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]], dtype=int32)},\n",
              "  array([1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "         0, 1, 1, 1, 1, 0, 0, 0, 1, 0]))]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iEUS77CIzgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bfa4c79-a269-4799-d907-f10574c3f040"
      },
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 37s 652ms/step - loss: 0.3441 - accuracy: 0.9061\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3441121578216553, 0.906095564365387]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4d1Hs-Dc4JE"
      },
      "source": [
        "## 5. Fine-tuning BERT for NLI\n",
        "\n",
        "Now that you know how to fine-tune BERT model for sentence classification. We could do something similar to fine-tune BERT to Natural Language Inference task. Recall that NLI consist in determining whether a natural language hypothesis can justifiably be inferred from a natural language premise hus given a pair of premise and hypothesis texts, the task is to classify them into three categories: entailment, contradiction, and neutral.\n",
        "\n",
        "There are many ways to approach the task, but one way is to encode the premise and hypothesis at the same time as shown in the figure below. We separate premise and hypothesis sentences with `[SEP]` and use `[CLS]` token to perform the three-way classification task. \n",
        "\n",
        "\n",
        " ![](http://ixa2.si.ehu.es/~jibloleo/uc3m_dl4nlp/img/bert_nli.png)\n",
        "\n",
        "----\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d50LA3brYajM"
      },
      "source": [
        "Let's start loading the data for NLI. We'll use the same function used in the previous lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujAiEm7BL-ZZ"
      },
      "source": [
        "import re\n",
        "import random\n",
        "import json\n",
        "import bz2\n",
        "import pandas as pd\n",
        "\n",
        "def load_snli_data(path, label_map = {\"entailment\": 0, \"neutral\": 1,\"contradiction\": 2}):\n",
        "    data = []\n",
        "    with bz2.open(path) as f:\n",
        "        for i, line in enumerate(f):\n",
        "            line = line.decode('utf-8')\n",
        "            if i >= 1000000:  # Edit to use less data for debugging. set to 1000000 for testing.\n",
        "                break\n",
        "            json_line = json.loads(line)\n",
        "            if json_line[\"gold_label\"] not in label_map:\n",
        "                continue\n",
        "            loaded_example = {}\n",
        "            loaded_example[\"label\"] = label_map[json_line[\"gold_label\"]]\n",
        "            loaded_example[\"sentence1\"] = json_line[\"sentence1\"]\n",
        "            loaded_example[\"sentence2\"] = json_line[\"sentence2\"]\n",
        "            data.append(loaded_example)\n",
        "    data = pd.DataFrame(data)\n",
        "    return data\n",
        "\n",
        "#snli_home = 'drive/My Drive/Colab Notebooks/2020-2021_labs/data/snli/' \n",
        "snli_home = 'drive/My Drive/Colab Notebooks/dl4nlp_labs/data/snli'\n",
        "training_set = load_snli_data(snli_home + '/snli_1.0_train.jsonl.bz2')\n",
        "dev_set = load_snli_data(snli_home + '/snli_1.0_dev.jsonl.bz2')\n",
        "test_set = load_snli_data(snli_home + '/snli_1.0_test.jsonl.bz2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksshZRh0lx8K"
      },
      "source": [
        "We are going to reduce the dataset to speed up the experiments in the lab session, but feel free to use the whole dataset after the lab is completed. Fine-tuning with the whole training set can take many hours, so maybe it is a good idea to run just for one or two epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHHI8N29Vtti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854d6731-0f9b-40ef-c0c3-b25e0291516b"
      },
      "source": [
        "training_set = training_set.head(5000)\n",
        "dev_set = dev_set.head(1000)\n",
        "\n",
        "# check if the dataset is still balanced\n",
        "print('Training labels:')\n",
        "print(training_set.label.value_counts())\n",
        "\n",
        "print('Dev labels:')\n",
        "print(dev_set.label.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training labels:\n",
            "0    1673\n",
            "2    1669\n",
            "1    1658\n",
            "Name: label, dtype: int64\n",
            "Dev labels:\n",
            "2    336\n",
            "1    333\n",
            "0    331\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiCVwyaGnFY4"
      },
      "source": [
        "Note that when we load the pretrained model (`from_pretrained`) we need to indicate number of labels that contains the dataset. This can be done with the argument `num_labels`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJdYaECRXN3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fefbeba-dee7-4120-cf90-f2a408cbf14f"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
        "\n",
        "nli_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=3)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX3s5Yp1rm0a"
      },
      "source": [
        "As you can see, the `config` has slightly changed compared to first model. Now it contains the information of the labels (we don't care about the actual id2label mapping for now)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fssORtQtfqwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f968cd-91e0-43c5-df2f-17a776bba1cb"
      },
      "source": [
        "nli_model.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"bert-base-cased\",\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"LABEL_0\",\n",
              "    \"1\": \"LABEL_1\",\n",
              "    \"2\": \"LABEL_2\"\n",
              "  },\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"label2id\": {\n",
              "    \"LABEL_0\": 0,\n",
              "    \"LABEL_1\": 1,\n",
              "    \"LABEL_2\": 2\n",
              "  },\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.15.0\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 28996\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIFdYyYkTRiF"
      },
      "source": [
        "### Exercise 3:\n",
        "For the final exercise you have to re-write the function `convert_examples_to_features` so it is able to extract the token ids of premise and hypothesis in one go. Most of the function is already done for you. You just need to fill a small part to complete it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zFQ2QNwXLoB"
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import InputFeatures\n",
        "\n",
        "def convert_nli_examples_to_features(premises, hypotheses, labels):\n",
        "  labels = list(labels)\n",
        "\n",
        "  # TODO: You need to create the code that fills the batch_encoding object. \n",
        "  # Hint: Iterate over premises and hypothesis to get tuples of \n",
        "  #       premises and hypotheses.\n",
        "\n",
        "  prem_hyp_list = [] #initialize the keeper\n",
        "\n",
        "  for p,h in zip(premises, hypotheses): #iterate: p for premises and h for hypotheses\n",
        "    prem_hyp_list.append((p,h))    #we put it inside the list\n",
        "  \n",
        "\n",
        "  batch_encoding = tokenizer.batch_encode_plus(\n",
        "        prem_hyp_list, max_length=128, pad_to_max_length=True,    #this is the same as before, but i changed \"sentence1\",\"sentence2\"\n",
        "    )\n",
        "\n",
        "  # batch_encoding = tokenizer.batch_encode_plus(\n",
        "  #       list(zip(premises,hypotheses)), max_length=128, pad_to_max_length=True,    \n",
        "  #   )\n",
        "\n",
        "  features = []\n",
        "  for i in range(len(premises)):\n",
        "      inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
        "\n",
        "      feature = InputFeatures(**inputs, label=labels[i])\n",
        "      features.append(feature)\n",
        "\n",
        "  for i in range(5):\n",
        "      print(\"*** Example ***\")\n",
        "      print(\"premise: %s\" % (premises[i]))\n",
        "      print(\"hypothesis: %s\" % (hypotheses[i]))\n",
        "      print(\"features: %s\" % features[i])\n",
        "\n",
        "  return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbdPeTBpryJl"
      },
      "source": [
        "Once you complete the exercise you can see convert dataset to features first and to `tf.dataset` after that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6BqLltF32ZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc0ba376-e71a-4b2d-c476-14ff04605913"
      },
      "source": [
        "train_features = convert_nli_examples_to_features(training_set.sentence1, training_set.sentence2, training_set.label)\n",
        "dev_features = convert_nli_examples_to_features(dev_set.sentence1, dev_set.sentence2, dev_set.label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Example ***\n",
            "premise: A person on a horse jumps over a broken down airplane.\n",
            "hypothesis: A person is training his horse for a competition.\n",
            "features: InputFeatures(input_ids=[101, 138, 1825, 1113, 170, 3241, 15457, 1166, 170, 3088, 1205, 15478, 119, 102, 138, 1825, 1110, 2013, 1117, 3241, 1111, 170, 2208, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "*** Example ***\n",
            "premise: A person on a horse jumps over a broken down airplane.\n",
            "hypothesis: A person is at a diner, ordering an omelette.\n",
            "features: InputFeatures(input_ids=[101, 138, 1825, 1113, 170, 3241, 15457, 1166, 170, 3088, 1205, 15478, 119, 102, 138, 1825, 1110, 1120, 170, 20162, 117, 13649, 1126, 184, 10212, 6347, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=2)\n",
            "*** Example ***\n",
            "premise: A person on a horse jumps over a broken down airplane.\n",
            "hypothesis: A person is outdoors, on a horse.\n",
            "features: InputFeatures(input_ids=[101, 138, 1825, 1113, 170, 3241, 15457, 1166, 170, 3088, 1205, 15478, 119, 102, 138, 1825, 1110, 23178, 117, 1113, 170, 3241, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "premise: Children smiling and waving at camera\n",
            "hypothesis: They are smiling at their parents\n",
            "features: InputFeatures(input_ids=[101, 4288, 5278, 1105, 12502, 1120, 4504, 102, 1220, 1132, 5278, 1120, 1147, 2153, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "*** Example ***\n",
            "premise: Children smiling and waving at camera\n",
            "hypothesis: There are children present\n",
            "features: InputFeatures(input_ids=[101, 4288, 5278, 1105, 12502, 1120, 4504, 102, 1247, 1132, 1482, 1675, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "premise: Two women are embracing while holding to go packages.\n",
            "hypothesis: The sisters are hugging goodbye while holding to go packages after just eating lunch.\n",
            "features: InputFeatures(input_ids=[101, 1960, 1535, 1132, 9712, 26348, 1229, 2355, 1106, 1301, 15611, 119, 102, 1109, 5919, 1132, 19558, 12903, 1229, 2355, 1106, 1301, 15611, 1170, 1198, 5497, 5953, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "*** Example ***\n",
            "premise: Two women are embracing while holding to go packages.\n",
            "hypothesis: Two woman are holding packages.\n",
            "features: InputFeatures(input_ids=[101, 1960, 1535, 1132, 9712, 26348, 1229, 2355, 1106, 1301, 15611, 119, 102, 1960, 1590, 1132, 2355, 15611, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "premise: Two women are embracing while holding to go packages.\n",
            "hypothesis: The men are fighting outside a deli.\n",
            "features: InputFeatures(input_ids=[101, 1960, 1535, 1132, 9712, 26348, 1229, 2355, 1106, 1301, 15611, 119, 102, 1109, 1441, 1132, 2935, 1796, 170, 3687, 1182, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=2)\n",
            "*** Example ***\n",
            "premise: Two young children in blue jerseys, one with the number 9 and one with the number 2 are standing on wooden steps in a bathroom and washing their hands in a sink.\n",
            "hypothesis: Two kids in numbered jerseys wash their hands.\n",
            "features: InputFeatures(input_ids=[101, 1960, 1685, 1482, 1107, 2221, 14953, 1116, 117, 1141, 1114, 1103, 1295, 130, 1105, 1141, 1114, 1103, 1295, 123, 1132, 2288, 1113, 4122, 3343, 1107, 170, 5056, 1105, 13445, 1147, 1493, 1107, 170, 7496, 119, 102, 1960, 4067, 1107, 8324, 14953, 1116, 10124, 1147, 1493, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "premise: Two young children in blue jerseys, one with the number 9 and one with the number 2 are standing on wooden steps in a bathroom and washing their hands in a sink.\n",
            "hypothesis: Two kids at a ballgame wash their hands.\n",
            "features: InputFeatures(input_ids=[101, 1960, 1685, 1482, 1107, 2221, 14953, 1116, 117, 1141, 1114, 1103, 1295, 130, 1105, 1141, 1114, 1103, 1295, 123, 1132, 2288, 1113, 4122, 3343, 1107, 170, 5056, 1105, 13445, 1147, 1493, 1107, 170, 7496, 119, 102, 1960, 4067, 1120, 170, 3240, 18350, 10124, 1147, 1493, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo2EphiZjeNv"
      },
      "source": [
        "train_dataset = convert_features_to_tf_dataset(train_features)\n",
        "dev_dataset = convert_features_to_tf_dataset(dev_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObN05ITRsWKe"
      },
      "source": [
        "We use `tf.dataset` API to shuffle the training set and set the batch size. We decrease the batch size to 16 in order to avoid problems with the memory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WECDX7kMctlT"
      },
      "source": [
        "train_dataset = train_dataset.shuffle(100).batch(16)\n",
        "dev_dataset = dev_dataset.batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxIlEzupXhG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc59c18-6745-4f73-dfe3-83b63c291eaf"
      },
      "source": [
        "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "nli_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "\n",
        "# Train and evaluate using tf.keras.Model.fit()\n",
        "history = nli_model.fit(train_dataset, epochs=3, validation_data=dev_dataset)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "313/313 [==============================] - 383s 1s/step - loss: 0.8063 - accuracy: 0.6450 - val_loss: 0.6085 - val_accuracy: 0.7540\n",
            "Epoch 2/3\n",
            "313/313 [==============================] - 356s 1s/step - loss: 0.4666 - accuracy: 0.8320 - val_loss: 0.5663 - val_accuracy: 0.7810\n",
            "Epoch 3/3\n",
            "313/313 [==============================] - 356s 1s/step - loss: 0.2916 - accuracy: 0.9070 - val_loss: 0.7773 - val_accuracy: 0.7850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_tYW0T8d_Qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e5949d-9e0f-4a23-b6d4-38d455f2721f"
      },
      "source": [
        "nli_model.predict(dev_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFSequenceClassifierOutput([('logits',\n",
              "                             array([[-1.4513462 ,  2.8288033 , -1.5245304 ],\n",
              "                                    [ 3.2899046 , -0.30286843, -2.4082422 ],\n",
              "                                    [-1.524397  , -2.3333085 ,  3.7131321 ],\n",
              "                                    ...,\n",
              "                                    [ 3.5304894 , -0.43668452, -2.4580462 ],\n",
              "                                    [-2.794487  , -1.7921312 ,  4.3554387 ],\n",
              "                                    [-1.2086835 , -0.43231574,  1.7279775 ]], dtype=float32))])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIgw-1Qot731"
      },
      "source": [
        "As in the previous example, we can process the test set in the same way, and evaluate it directly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXrIqumjt7XP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe13d593-673a-43dd-c866-5d466cc4ddf6"
      },
      "source": [
        "test_features = convert_nli_examples_to_features(test_set.sentence1,\n",
        "                                                 test_set.sentence2,\n",
        "                                                 test_set.label)\n",
        "test_dataset = convert_features_to_tf_dataset(test_features)\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Example ***\n",
            "premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n",
            "hypothesis: The church has cracks in the ceiling.\n",
            "features: InputFeatures(input_ids=[101, 1188, 1749, 8041, 12792, 1106, 1103, 12980, 1112, 1152, 6928, 8730, 2285, 2040, 1121, 1103, 1520, 1120, 170, 1749, 119, 102, 1109, 1749, 1144, 16694, 1107, 1103, 5265, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "*** Example ***\n",
            "premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n",
            "hypothesis: The church is filled with song.\n",
            "features: InputFeatures(input_ids=[101, 1188, 1749, 8041, 12792, 1106, 1103, 12980, 1112, 1152, 6928, 8730, 2285, 2040, 1121, 1103, 1520, 1120, 170, 1749, 119, 102, 1109, 1749, 1110, 2709, 1114, 1461, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n",
            "hypothesis: A choir singing at a baseball game.\n",
            "features: InputFeatures(input_ids=[101, 1188, 1749, 8041, 12792, 1106, 1103, 12980, 1112, 1152, 6928, 8730, 2285, 2040, 1121, 1103, 1520, 1120, 170, 1749, 119, 102, 138, 8041, 4241, 1120, 170, 3866, 1342, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=2)\n",
            "*** Example ***\n",
            "premise: A woman with a green headscarf, blue shirt and a very big grin.\n",
            "hypothesis: The woman is young.\n",
            "features: InputFeatures(input_ids=[101, 138, 1590, 1114, 170, 2448, 4075, 8766, 2087, 117, 2221, 2969, 1105, 170, 1304, 1992, 5207, 119, 102, 1109, 1590, 1110, 1685, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "*** Example ***\n",
            "premise: A woman with a green headscarf, blue shirt and a very big grin.\n",
            "hypothesis: The woman is very happy.\n",
            "features: InputFeatures(input_ids=[101, 138, 1590, 1114, 170, 2448, 4075, 8766, 2087, 117, 2221, 2969, 1105, 170, 1304, 1992, 5207, 119, 102, 1109, 1590, 1110, 1304, 2816, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrwjUrcKulfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1224eda4-ef01-4090-969d-1d852a820320"
      },
      "source": [
        "nli_model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "307/307 [==============================] - 200s 651ms/step - loss: 0.7334 - accuracy: 0.7891\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.733420193195343, 0.7890879511833191]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qSPPPKqQxCS"
      },
      "source": [
        "### Exercise 4\n",
        "If you have time increase the size of the trainig set. Try with 15,000 training examples, and see what happens in the test set. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training_set = load_snli_data(snli_home + '/snli_1.0_train.jsonl.bz2')\n",
        "# training_set = training_set.head(15000)  \n",
        "\n",
        "# train_features = convert_nli_examples_to_features(training_set.sentence1, training_set.sentence2, training_set.label)\n",
        "# train_dataset = convert_features_to_tf_dataset(train_features)\n",
        "# train_dataset = train_dataset.shuffle(100).batch(16)\n",
        "\n",
        "# # Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "# metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "# nli_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "\n",
        "# # Train and evaluate using tf.keras.Model.fit()\n",
        "# history = model.fit(train_dataset, epochs=3, validation_data=dev_dataset)\n",
        "\n",
        "\n",
        "# nli_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "C50lV_Aegysd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snli_home = 'drive/My Drive/Colab Notebooks/dl4nlp_labs/data/snli'\n",
        "training_set = load_snli_data(snli_home + '/snli_1.0_train.jsonl.bz2')\n",
        "dev_set = load_snli_data(snli_home + '/snli_1.0_dev.jsonl.bz2')\n",
        "test_set = load_snli_data(snli_home + '/snli_1.0_test.jsonl.bz2')\n",
        "\n",
        "training_set = training_set.head(15000)\n",
        "dev_set = dev_set.head(1000)\n",
        "\n",
        "# check if the dataset is still balanced\n",
        "print('Training labels:')\n",
        "print(training_set.label.value_counts())\n",
        "\n",
        "print('Dev labels:')\n",
        "print(dev_set.label.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzabyux2SD3A",
        "outputId": "2f612a10-9b00-473c-ef1e-3dea6b2cd577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training labels:\n",
            "0    5013\n",
            "2    4995\n",
            "1    4992\n",
            "Name: label, dtype: int64\n",
            "Dev labels:\n",
            "2    336\n",
            "1    333\n",
            "0    331\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
        "\n",
        "nli_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=3)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVm1kZ-4hs9a",
        "outputId": "fb25deba-90f9-4c63-dce8-f0acaa5be3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nli_model.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gOTVTrbhvOO",
        "outputId": "d203ffae-2909-40b3-b8de-8878ccd90360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"bert-base-cased\",\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"LABEL_0\",\n",
              "    \"1\": \"LABEL_1\",\n",
              "    \"2\": \"LABEL_2\"\n",
              "  },\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"label2id\": {\n",
              "    \"LABEL_0\": 0,\n",
              "    \"LABEL_1\": 1,\n",
              "    \"LABEL_2\": 2\n",
              "  },\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.15.0\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 28996\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = convert_nli_examples_to_features(training_set.sentence1, training_set.sentence2, training_set.label)\n",
        "dev_features = convert_nli_examples_to_features(dev_set.sentence1, dev_set.sentence2, dev_set.label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaIbsdsrhz6o",
        "outputId": "4f5388dd-5341-4f05-ce29-8f58f9120b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Example ***\n",
            "premise: A person on a horse jumps over a broken down airplane.\n",
            "hypothesis: A person is training his horse for a competition.\n",
            "features: InputFeatures(input_ids=[101, 138, 1825, 1113, 170, 3241, 15457, 1166, 170, 3088, 1205, 15478, 119, 102, 138, 1825, 1110, 2013, 1117, 3241, 1111, 170, 2208, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "*** Example ***\n",
            "premise: A person on a horse jumps over a broken down airplane.\n",
            "hypothesis: A person is at a diner, ordering an omelette.\n",
            "features: InputFeatures(input_ids=[101, 138, 1825, 1113, 170, 3241, 15457, 1166, 170, 3088, 1205, 15478, 119, 102, 138, 1825, 1110, 1120, 170, 20162, 117, 13649, 1126, 184, 10212, 6347, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=2)\n",
            "*** Example ***\n",
            "premise: A person on a horse jumps over a broken down airplane.\n",
            "hypothesis: A person is outdoors, on a horse.\n",
            "features: InputFeatures(input_ids=[101, 138, 1825, 1113, 170, 3241, 15457, 1166, 170, 3088, 1205, 15478, 119, 102, 138, 1825, 1110, 23178, 117, 1113, 170, 3241, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "premise: Children smiling and waving at camera\n",
            "hypothesis: They are smiling at their parents\n",
            "features: InputFeatures(input_ids=[101, 4288, 5278, 1105, 12502, 1120, 4504, 102, 1220, 1132, 5278, 1120, 1147, 2153, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "*** Example ***\n",
            "premise: Children smiling and waving at camera\n",
            "hypothesis: There are children present\n",
            "features: InputFeatures(input_ids=[101, 4288, 5278, 1105, 12502, 1120, 4504, 102, 1247, 1132, 1482, 1675, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "premise: Two women are embracing while holding to go packages.\n",
            "hypothesis: The sisters are hugging goodbye while holding to go packages after just eating lunch.\n",
            "features: InputFeatures(input_ids=[101, 1960, 1535, 1132, 9712, 26348, 1229, 2355, 1106, 1301, 15611, 119, 102, 1109, 5919, 1132, 19558, 12903, 1229, 2355, 1106, 1301, 15611, 1170, 1198, 5497, 5953, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "*** Example ***\n",
            "premise: Two women are embracing while holding to go packages.\n",
            "hypothesis: Two woman are holding packages.\n",
            "features: InputFeatures(input_ids=[101, 1960, 1535, 1132, 9712, 26348, 1229, 2355, 1106, 1301, 15611, 119, 102, 1960, 1590, 1132, 2355, 15611, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "premise: Two women are embracing while holding to go packages.\n",
            "hypothesis: The men are fighting outside a deli.\n",
            "features: InputFeatures(input_ids=[101, 1960, 1535, 1132, 9712, 26348, 1229, 2355, 1106, 1301, 15611, 119, 102, 1109, 1441, 1132, 2935, 1796, 170, 3687, 1182, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=2)\n",
            "*** Example ***\n",
            "premise: Two young children in blue jerseys, one with the number 9 and one with the number 2 are standing on wooden steps in a bathroom and washing their hands in a sink.\n",
            "hypothesis: Two kids in numbered jerseys wash their hands.\n",
            "features: InputFeatures(input_ids=[101, 1960, 1685, 1482, 1107, 2221, 14953, 1116, 117, 1141, 1114, 1103, 1295, 130, 1105, 1141, 1114, 1103, 1295, 123, 1132, 2288, 1113, 4122, 3343, 1107, 170, 5056, 1105, 13445, 1147, 1493, 1107, 170, 7496, 119, 102, 1960, 4067, 1107, 8324, 14953, 1116, 10124, 1147, 1493, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "premise: Two young children in blue jerseys, one with the number 9 and one with the number 2 are standing on wooden steps in a bathroom and washing their hands in a sink.\n",
            "hypothesis: Two kids at a ballgame wash their hands.\n",
            "features: InputFeatures(input_ids=[101, 1960, 1685, 1482, 1107, 2221, 14953, 1116, 117, 1141, 1114, 1103, 1295, 130, 1105, 1141, 1114, 1103, 1295, 123, 1132, 2288, 1113, 4122, 3343, 1107, 170, 5056, 1105, 13445, 1147, 1493, 1107, 170, 7496, 119, 102, 1960, 4067, 1120, 170, 3240, 18350, 10124, 1147, 1493, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = convert_features_to_tf_dataset(train_features)\n",
        "dev_dataset = convert_features_to_tf_dataset(dev_features)"
      ],
      "metadata": {
        "id": "MFTnmR8Rh9vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.shuffle(100).batch(16)\n",
        "dev_dataset = dev_dataset.batch(32)"
      ],
      "metadata": {
        "id": "h_VPY86viD1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "nli_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "\n",
        "# Train and evaluate using tf.keras.Model.fit()\n",
        "history = nli_model.fit(train_dataset, epochs=3, validation_data=dev_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHgeP81IiJdB",
        "outputId": "6b8b66a4-a900-4009-83d8-2ef25456c3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "938/938 [==============================] - 1052s 1s/step - loss: 0.6523 - accuracy: 0.7267 - val_loss: 0.4713 - val_accuracy: 0.8260\n",
            "Epoch 2/3\n",
            "938/938 [==============================] - 1026s 1s/step - loss: 0.3674 - accuracy: 0.8646 - val_loss: 0.4945 - val_accuracy: 0.8250\n",
            "Epoch 3/3\n",
            "938/938 [==============================] - 1028s 1s/step - loss: 0.2190 - accuracy: 0.9261 - val_loss: 0.5732 - val_accuracy: 0.8080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nli_model.predict(dev_dataset)"
      ],
      "metadata": {
        "id": "Y-OXV93-iRYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707d4f17-9dd8-457c-a763-eaf0c74813d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFSequenceClassifierOutput([('logits',\n",
              "                             array([[-2.8772044 ,  3.5953496 , -2.121178  ],\n",
              "                                    [ 4.175285  , -1.2843221 , -2.9615135 ],\n",
              "                                    [-4.6051316 , -1.4041612 ,  6.0987124 ],\n",
              "                                    ...,\n",
              "                                    [ 3.2546473 , -1.1076367 , -2.3874798 ],\n",
              "                                    [-4.225372  ,  1.3368548 ,  2.4894009 ],\n",
              "                                    [-2.3129811 ,  1.7740891 , -0.37037638]], dtype=float32))])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_features = convert_nli_examples_to_features(test_set.sentence1,\n",
        "                                                 test_set.sentence2,\n",
        "                                                 test_set.label)\n",
        "test_dataset = convert_features_to_tf_dataset(test_features)\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "metadata": {
        "id": "I7l2ywHfiSMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be8e133-e32d-4c40-8f3f-3410472ba48d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Example ***\n",
            "premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n",
            "hypothesis: The church has cracks in the ceiling.\n",
            "features: InputFeatures(input_ids=[101, 1188, 1749, 8041, 12792, 1106, 1103, 12980, 1112, 1152, 6928, 8730, 2285, 2040, 1121, 1103, 1520, 1120, 170, 1749, 119, 102, 1109, 1749, 1144, 16694, 1107, 1103, 5265, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "*** Example ***\n",
            "premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n",
            "hypothesis: The church is filled with song.\n",
            "features: InputFeatures(input_ids=[101, 1188, 1749, 8041, 12792, 1106, 1103, 12980, 1112, 1152, 6928, 8730, 2285, 2040, 1121, 1103, 1520, 1120, 170, 1749, 119, 102, 1109, 1749, 1110, 2709, 1114, 1461, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
            "*** Example ***\n",
            "premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n",
            "hypothesis: A choir singing at a baseball game.\n",
            "features: InputFeatures(input_ids=[101, 1188, 1749, 8041, 12792, 1106, 1103, 12980, 1112, 1152, 6928, 8730, 2285, 2040, 1121, 1103, 1520, 1120, 170, 1749, 119, 102, 138, 8041, 4241, 1120, 170, 3866, 1342, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=2)\n",
            "*** Example ***\n",
            "premise: A woman with a green headscarf, blue shirt and a very big grin.\n",
            "hypothesis: The woman is young.\n",
            "features: InputFeatures(input_ids=[101, 138, 1590, 1114, 170, 2448, 4075, 8766, 2087, 117, 2221, 2969, 1105, 170, 1304, 1992, 5207, 119, 102, 1109, 1590, 1110, 1685, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "*** Example ***\n",
            "premise: A woman with a green headscarf, blue shirt and a very big grin.\n",
            "hypothesis: The woman is very happy.\n",
            "features: InputFeatures(input_ids=[101, 138, 1590, 1114, 170, 2448, 4075, 8766, 2087, 117, 2221, 2969, 1105, 170, 1304, 1992, 5207, 119, 102, 1109, 1590, 1110, 1304, 2816, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nli_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "l4BvVvrSiYL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b23a647-75fb-4a62-d3d6-cb9d946ea44c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "307/307 [==============================] - 200s 652ms/step - loss: 0.6429 - accuracy: 0.8118\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6428697109222412, 0.811787486076355]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjBUT-D2spyT"
      },
      "source": [
        "# Atribution:\n",
        "Adapted by Oier Lopez de Lacalle and Ander Barrena"
      ]
    }
  ]
}